{"name": "Vladimir Vapnik", "content": "Vladimir Naumovich Vapnik (Russian: \u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440 \u041d\u0430\u0443\u043c\u043e\u0432\u0438\u0447 \u0412\u0430\u043f\u043d\u0438\u043a; born 6 December 1936) is one of the main developers of the Vapnik\u2013Chervonenkis theory of statistical learning,[1] and the co-inventor of the support-vector machine method, and support-vector clustering algorithm.[2]\n Vladimir Vapnik was born to a Jewish family[3] in the Soviet Union. He received his master's degree in mathematics from the Uzbek State University, Samarkand, Uzbek SSR in 1958 and Ph.D in statistics at the Institute of Control Sciences, Moscow in 1964. He worked at this institute from 1961 to 1990 and became Head of the Computer Science Research Department.[4]\n At the end of 1990, Vladimir Vapnik moved to the USA and joined the Adaptive Systems Research Department at AT&T Bell Labs in Holmdel, New Jersey. While at AT&T, Vapnik and his colleagues did work on the support-vector machine. They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition. The group later became the Image Processing Research Department of AT&T Laboratories when AT&T spun off Lucent Technologies in 1996. In 2000, Vapnik and neural networks expert, Hava Siegelmann developed Support-Vector Clustering, which enabled the algorithm to categorize inputs without labels - becoming one of the most ubiquitous data clustering applications in use. Vapnik left AT&T in 2002 and joined NEC Laboratories in Princeton, New Jersey, where he worked in the Machine Learning group. He also holds a Professor of Computer Science and Statistics position at Royal Holloway, University of London since 1995, as well as a position as Professor of Computer Science at Columbia University, New York City since 2003.[5] As of February 1, 2021, he has an h-index of 86 and, overall, his publications have been cited 226597 times.[6] His book on \"The Nature of Statistical Learning Theory\" alone has been cited 91650 times.\n On November 25, 2014, Vapnik joined Facebook AI Research,[7] where he is working alongside his longtime collaborators Jason Weston, L\u00e9on Bottou, Ronan Collobert, and Yann LeCun.[8]\nIn 2016, he also joined Vencore Labs.\n Vladimir Vapnik was inducted into the U.S. National Academy of Engineering in 2006. He received the 2005 Gabor Award,[9] the 2008 Paris Kanellakis Award, the 2010 Neural Networks Pioneer Award,[10] the 2012 IEEE Frank Rosenblatt Award, the 2012 Benjamin Franklin Medal in Computer and Cognitive Science from the Franklin Institute,[4] the 2013 C&C Prize from the NEC C&C Foundation,[11] the 2014 Kamp\u00e9 de F\u00e9riet Award, the 2017 \nIEEE John von Neumann Medal.[12] In 2018, he received the Kolmogorov Medal[13] from University of London and delivered the Kolmogorov Lecture. In 2019, Vladimir Vapnik received \nBBVA Foundation Frontiers of Knowledge Award.\n ", "tags": ["Academics of Royal Holloway, University of London", "Living people", "Columbia University faculty", "Columbia School of Engineering and Applied Science faculty", "Machine learning researchers", "Soviet emigrants to the United States", "Soviet computer scientists", "Soviet mathematicians", "American mathematicians", "American computer scientists", "Russian Jews", "Members of the United States National Academy of Engineering", "1936 births", "Jewish scientists", "Scientists at Bell Labs", "CS1 maint: extra text: authors list", "Articles with hCards", "Articles containing Russian-language text", "Wikipedia articles with BNF identifiers", "Wikipedia articles with DBLP identifiers", "Wikipedia articles with GND identifiers", "Wikipedia articles with ISNI identifiers", "Wikipedia articles with LCCN identifiers", "Wikipedia articles with MGP identifiers", "Wikipedia articles with NKC identifiers", "Wikipedia articles with NTA identifiers", "Wikipedia articles with SELIBR identifiers", "Wikipedia articles with SUDOC identifiers", "Wikipedia articles with Trove identifiers", "Wikipedia articles with VIAF identifiers", "Wikipedia articles with WORLDCATID identifiers"], "raw": "Vladimir N. VapnikBorn (1936-12-06) December 6, 1936 (age\u00a084)Soviet UnionAlma\u00a0materInstitute of Control Sciences, Russian Academy of SciencesUzbek State UniversityKnown\u00a0forVapnik\u2013Chervonenkis theoryVapnik\u2013Chervonenkis dimensionSupport-vector machineSupport-vector clustering algorithmStatistical learning theoryStructural risk minimizationAwardsKolmogorov Medal (2018)IEEE John von Neumann Medal (2017)Kamp\u00e9 de F\u00e9riet Award (2014)C&C Prize (2013)Benjamin Franklin Medal (2012) IEEE Frank Rosenblatt Award (2012)IEEE Neural Networks Pioneer Award (2010)  Paris Kanellakis Award (2008)Fellow of the U.S. National Academy of Engineering (2006)Gabor Award, International Neural Network Society (2005)Alexander Humboldt Research Award (2003)Scientific careerFieldsMachine learningStatisticsInstitutionsFacebook Artificial Intelligence ResearchVencore LabsNEC Laboratories AmericaAdaptive Systems Research\nDepartment, AT&T Bell LaboratoriesRoyal Holloway, University of LondonColumbia UniversityDoctoral advisorAlexander Lerner\n\nVladimir Naumovich Vapnik (Russian: \u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440 \u041d\u0430\u0443\u043c\u043e\u0432\u0438\u0447 \u0412\u0430\u043f\u043d\u0438\u043a; born 6 December 1936) is one of the main developers of the Vapnik\u2013Chervonenkis theory of statistical learning,[1] and the co-inventor of the support-vector machine method, and support-vector clustering algorithm.[2]\n\nContents\n\n1 Early life and education\n2 Academic career\n3 Honors and awards\n4 Selected publications\n5 See also\n6 References\n7 External links\n\n\nEarly life and education[edit]\nVladimir Vapnik was born to a Jewish family[3] in the Soviet Union. He received his master's degree in mathematics from the Uzbek State University, Samarkand, Uzbek SSR in 1958 and Ph.D in statistics at the Institute of Control Sciences, Moscow in 1964. He worked at this institute from 1961 to 1990 and became Head of the Computer Science Research Department.[4]\n\nAcademic career[edit]\nAt the end of 1990, Vladimir Vapnik moved to the USA and joined the Adaptive Systems Research Department at AT&T Bell Labs in Holmdel, New Jersey. While at AT&T, Vapnik and his colleagues did work on the support-vector machine. They demonstrated its performance on a number of problems of interest to the machine learning community, including handwriting recognition. The group later became the Image Processing Research Department of AT&T Laboratories when AT&T spun off Lucent Technologies in 1996. In 2000, Vapnik and neural networks expert, Hava Siegelmann developed Support-Vector Clustering, which enabled the algorithm to categorize inputs without labels - becoming one of the most ubiquitous data clustering applications in use. Vapnik left AT&T in 2002 and joined NEC Laboratories in Princeton, New Jersey, where he worked in the Machine Learning group. He also holds a Professor of Computer Science and Statistics position at Royal Holloway, University of London since 1995, as well as a position as Professor of Computer Science at Columbia University, New York City since 2003.[5] As of February 1, 2021, he has an h-index of 86 and, overall, his publications have been cited 226597 times.[6] His book on \"The Nature of Statistical Learning Theory\" alone has been cited 91650 times.\nOn November 25, 2014, Vapnik joined Facebook AI Research,[7] where he is working alongside his longtime collaborators Jason Weston, L\u00e9on Bottou, Ronan Collobert, and Yann LeCun.[8]\nIn 2016, he also joined Vencore Labs.\n\nHonors and awards[edit]\nVladimir Vapnik was inducted into the U.S. National Academy of Engineering in 2006. He received the 2005 Gabor Award,[9] the 2008 Paris Kanellakis Award, the 2010 Neural Networks Pioneer Award,[10] the 2012 IEEE Frank Rosenblatt Award, the 2012 Benjamin Franklin Medal in Computer and Cognitive Science from the Franklin Institute,[4] the 2013 C&C Prize from the NEC C&C Foundation,[11] the 2014 Kamp\u00e9 de F\u00e9riet Award, the 2017 \nIEEE John von Neumann Medal.[12] In 2018, he received the Kolmogorov Medal[13] from University of London and delivered the Kolmogorov Lecture. In 2019, Vladimir Vapnik received \nBBVA Foundation Frontiers of Knowledge Award.\n\nSelected publications[edit]\nOn the uniform convergence of relative frequencies of events to their probabilities, co-author A. Y. Chervonenkis, 1971\nNecessary and sufficient conditions for the uniform convergence of means to their expectations, co-author A. Y. Chervonenkis, 1981\nEstimation of Dependences Based on Empirical Data, 1982\nThe Nature of Statistical Learning Theory, 1995\nStatistical Learning Theory (1998). Wiley-Interscience, ISBN\u00a00-471-03003-1.\nEstimation of Dependences Based on Empirical Data, Reprint 2006 (Springer), also contains a philosophical essay on Empirical Inference Science, 2006\nSee also[edit]\nAlexey Chervonenkis\nReferences[edit]\n\n\n^ The Nature of Statistical Learning Theory | Vladimir Vapnik | Springer.\n\n^ Cortes, Corinna; Vapnik, Vladimir (1995-09-01). \"Support-vector networks\". Machine Learning. 20 (3): 273\u2013297. CiteSeerX\u00a010.1.1.15.9362. doi:10.1007/BF00994018. ISSN\u00a00885-6125. S2CID\u00a0206787478.\n\n^ Estimation of Dependences Based on Empirical Data, (Springer Science & Business Media, 28 Sep 2006), By V. Vapnik, page 424\n\n^ a b \"Benjamin Franklin Medal in Computer and Cognitive Science\". Franklin Institute. 2012. Retrieved April 6, 2013.\n\n^ Scholkopf, Bernhard et al (eds) (2013). \"Preface\". Empirical Inference: Festschrift in Honor of Vladimir N. Vapnik. Springer. ISBN\u00a0978-3-642-41136-6.CS1 maint: extra text: authors list (link)\n\n^ \"Google Scholar Record of Vapnik\".\n\n^ \"Facebook AI Research\". FAIR. Retrieved 2016-09-20.; \"see also\" \"Facebook Research, (\"People\" entry for \"Vladimir Vapnik\")\". Retrieved 2017-09-06.\n\n^ \"Facebook's AI team hires Vladimir Vapnik, father of the popular support vector machine algorithm\". VentureBeat. 2014. Retrieved November 28, 2014.\n\n^ \"INNS awards recipients\". International Neural Network Society. 2005. Retrieved November 28, 2014.\n\n^ IEEE Computational Intelligence Society.\n\n^ \n\"NEC C&C Foundation Awards 2013 C&C Prize\". NEC. 2013. Retrieved December 3, 2013.\n\n^ \"IEEE JOHN VON NEUMANN MEDAL RECIPIENTS\" (PDF).\n\n^ \"Kolmogorov Lecture and Medal\".\n\n\nExternal links[edit]\nPhotograph of Professor Vapnik\nVapnik's brief biography from the Computer Learning Research Centre, Royal Holloway\nInterview by Lex Fridman\nvteWinners of the Paris Kanellakis Theory and Practice Award\nAdleman, Diffie, Hellman, Merkle, Rivest, Shamir (1996)\nLempel, Ziv (1997)\nBryant, Clarke, Emerson, McMillan (1998)\nSleator, Tarjan (1999)\nKarmarkar (2000)\nMyers (2001)\nFranaszek (2002)\nMiller, Rabin, Solovay, Strassen (2003)\nFreund, Schapire (2004)\nHolzmann, Kurshan, Vardi, Wolper (2005)\nBrayton (2006)\nBuchberger (2007)\nCortes, Vapnik (2008)\nBellare, Rogaway (2009)\nMehlhorn (2010)\nSamet (2011)\nBroder, Charikar, Indyk (2012)\nBlumofe, Leiserson (2013)\nDemmel (2014)\nLuby (2015)\nFiat, Naor (2016)\nShenker (2017)\nPevzner (2018)\nAlon, Gibbons, Matias, Szegedy (2019)\n\nAuthority control \nBNF: cb12503901v (data)\nDBLP: 31/6484\nGND: 1060237032\nISNI: 0000 0001 0929 4031\nLCCN: n80050226\nMGP: 204970\nNKC: uk2009539234\nNTA: 069554390\nSELIBR: 315455\nSUDOC: 034266208\nTrove: 868384\nVIAF: 101595313\n WorldCat Identities: lccn-n80050226\n\n\n\n\n", "Vladimir": 0.012531328320802004, "Naumovich": 0.002506265664160401, "Vapnik": 0.022556390977443608, "Russian": 0.002506265664160401, "\u0412\u043b\u0430\u0434\u0438\u043c\u0438\u0440": 0.002506265664160401, "\u041d\u0430\u0443\u043c\u043e\u0432\u0438\u0447": 0.002506265664160401, "\u0412\u0430\u043f\u043d\u0438\u043a": 0.002506265664160401, "born": 0.005012531328320802, "December": 0.002506265664160401, "is": 0.005012531328320802, "one": 0.005012531328320802, "of": 0.05012531328320802, "the": 0.07518796992481203, "main": 0.002506265664160401, "developers": 0.002506265664160401, "VapnikChervonenkis": 0.002506265664160401, "theory": 0.002506265664160401, "statistical": 0.002506265664160401, "learning": 0.005012531328320802, "and": 0.03258145363408521, "coinventor": 0.002506265664160401, "supportvector": 0.007518796992481203, "machine": 0.007518796992481203, "method": 0.002506265664160401, "clustering": 0.005012531328320802, "algorithm": 0.005012531328320802, "was": 0.005012531328320802, "to": 0.012531328320802004, "a": 0.010025062656641603, "Jewish": 0.002506265664160401, "family": 0.002506265664160401, "in": 0.03258145363408521, "Soviet": 0.002506265664160401, "Union": 0.002506265664160401, "He": 0.010025062656641603, "received": 0.010025062656641603, "his": 0.010025062656641603, "masters": 0.002506265664160401, "degree": 0.002506265664160401, "mathematics": 0.002506265664160401, "from": 0.012531328320802004, "Uzbek": 0.005012531328320802, "State": 0.002506265664160401, "University": 0.010025062656641603, "Samarkand": 0.002506265664160401, "SSR": 0.002506265664160401, "PhD": 0.002506265664160401, "statistics": 0.002506265664160401, "at": 0.015037593984962405, "Institute": 0.005012531328320802, "Control": 0.002506265664160401, "Sciences": 0.002506265664160401, "Moscow": 0.002506265664160401, "worked": 0.005012531328320802, "this": 0.002506265664160401, "institute": 0.002506265664160401, "became": 0.005012531328320802, "Head": 0.002506265664160401, "Computer": 0.010025062656641603, "Science": 0.010025062656641603, "Research": 0.010025062656641603, "Department": 0.007518796992481203, "At": 0.002506265664160401, "end": 0.002506265664160401, "moved": 0.002506265664160401, "USA": 0.002506265664160401, "joined": 0.010025062656641603, "Adaptive": 0.002506265664160401, "Systems": 0.002506265664160401, "ATT": 0.012531328320802004, "Bell": 0.002506265664160401, "Labs": 0.005012531328320802, "Holmdel": 0.002506265664160401, "New": 0.007518796992481203, "Jersey": 0.005012531328320802, "While": 0.002506265664160401, "colleagues": 0.002506265664160401, "did": 0.002506265664160401, "work": 0.002506265664160401, "on": 0.007518796992481203, "They": 0.002506265664160401, "demonstrated": 0.002506265664160401, "its": 0.002506265664160401, "performance": 0.002506265664160401, "number": 0.002506265664160401, "problems": 0.002506265664160401, "interest": 0.002506265664160401, "community": 0.002506265664160401, "including": 0.002506265664160401, "handwriting": 0.002506265664160401, "recognition": 0.002506265664160401, "The": 0.005012531328320802, "group": 0.005012531328320802, "later": 0.002506265664160401, "Image": 0.002506265664160401, "Processing": 0.002506265664160401, "Laboratories": 0.005012531328320802, "when": 0.002506265664160401, "spun": 0.002506265664160401, "off": 0.002506265664160401, "Lucent": 0.002506265664160401, "Technologies": 0.002506265664160401, "In": 0.007518796992481203, "neural": 0.002506265664160401, "networks": 0.002506265664160401, "expert": 0.002506265664160401, "Hava": 0.002506265664160401, "Siegelmann": 0.002506265664160401, "developed": 0.002506265664160401, "SupportVector": 0.002506265664160401, "Clustering": 0.002506265664160401, "which": 0.002506265664160401, "enabled": 0.002506265664160401, "categorize": 0.002506265664160401, "inputs": 0.002506265664160401, "without": 0.002506265664160401, "labels": 0.002506265664160401, "becoming": 0.002506265664160401, "most": 0.002506265664160401, "ubiquitous": 0.002506265664160401, "data": 0.002506265664160401, "applications": 0.002506265664160401, "use": 0.002506265664160401, "left": 0.002506265664160401, "NEC": 0.005012531328320802, "Princeton": 0.002506265664160401, "where": 0.005012531328320802, "he": 0.012531328320802004, "Machine": 0.002506265664160401, "Learning": 0.005012531328320802, "also": 0.005012531328320802, "holds": 0.002506265664160401, "Professor": 0.005012531328320802, "Statistics": 0.002506265664160401, "position": 0.005012531328320802, "Royal": 0.002506265664160401, "Holloway": 0.002506265664160401, "London": 0.005012531328320802, "since": 0.005012531328320802, "as": 0.007518796992481203, "well": 0.002506265664160401, "Columbia": 0.002506265664160401, "York": 0.002506265664160401, "City": 0.002506265664160401, "As": 0.002506265664160401, "February": 0.002506265664160401, "has": 0.005012531328320802, "an": 0.002506265664160401, "hindex": 0.002506265664160401, "overall": 0.002506265664160401, "publications": 0.002506265664160401, "have": 0.002506265664160401, "been": 0.005012531328320802, "cited": 0.005012531328320802, "times": 0.005012531328320802, "His": 0.002506265664160401, "book": 0.002506265664160401, "Nature": 0.002506265664160401, "Statistical": 0.002506265664160401, "Theory": 0.002506265664160401, "alone": 0.002506265664160401, "On": 0.002506265664160401, "November": 0.002506265664160401, "Facebook": 0.002506265664160401, "AI": 0.002506265664160401, "working": 0.002506265664160401, "alongside": 0.002506265664160401, "longtime": 0.002506265664160401, "collaborators": 0.002506265664160401, "Jason": 0.002506265664160401, "Weston": 0.002506265664160401, "L\u00e9on": 0.002506265664160401, "Bottou": 0.002506265664160401, "Ronan": 0.002506265664160401, "Collobert": 0.002506265664160401, "Yann": 0.002506265664160401, "LeCunIn": 0.002506265664160401, "Vencore": 0.002506265664160401, "inducted": 0.002506265664160401, "into": 0.002506265664160401, "US": 0.002506265664160401, "National": 0.002506265664160401, "Academy": 0.002506265664160401, "Engineering": 0.002506265664160401, "Gabor": 0.002506265664160401, "Award": 0.015037593984962405, "Paris": 0.002506265664160401, "Kanellakis": 0.002506265664160401, "Neural": 0.002506265664160401, "Networks": 0.002506265664160401, "Pioneer": 0.002506265664160401, "IEEE": 0.005012531328320802, "Frank": 0.002506265664160401, "Rosenblatt": 0.002506265664160401, "Benjamin": 0.002506265664160401, "Franklin": 0.005012531328320802, "Medal": 0.007518796992481203, "Cognitive": 0.002506265664160401, "CC": 0.005012531328320802, "Prize": 0.002506265664160401, "Foundation": 0.005012531328320802, "Kamp\u00e9": 0.002506265664160401, "de": 0.002506265664160401, "F\u00e9riet": 0.002506265664160401, "John": 0.002506265664160401, "von": 0.002506265664160401, "Neumann": 0.002506265664160401, "Kolmogorov": 0.005012531328320802, "delivered": 0.002506265664160401, "Lecture": 0.002506265664160401, "BBVA": 0.002506265664160401, "Frontiers": 0.002506265664160401, "Knowledge": 0.002506265664160401, "total": 399}